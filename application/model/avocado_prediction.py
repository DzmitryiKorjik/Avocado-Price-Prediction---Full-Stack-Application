# ============================================================================
# ğŸ¥‘ MODÃˆLE PRÃ‰DICTIF POUR LE PRIX DES AVOCATS
# ============================================================================
# Ce script prÃ©dit le prix moyen des avocats aux Ã‰tats-Unis en utilisant
# un modÃ¨le de machine learning (XGBoost).
# ============================================================================

# =============================================================================
# IMPORTS
# =============================================================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import os
import joblib

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor

# Configuration de l'affichage
pd.set_option('display.max_columns', None)
plt.style.use('seaborn-v0_8-whitegrid')

print("âœ… BibliothÃ¨ques importÃ©es avec succÃ¨s !")

# =============================================================================
# Ã‰TAPE 1 : IMPORTER ET EXPLORER LES DONNÃ‰ES
# =============================================================================
print("\n" + "=" * 60)
print("ğŸ“Š Ã‰TAPE 1 : IMPORTER ET EXPLORER LES DONNÃ‰ES")
print("=" * 60)

# 1.1 Charger les donnÃ©es
df = pd.read_csv('avocado.csv')
print(f"\nğŸ“Š Dimensions du dataset : {df.shape[0]} lignes Ã— {df.shape[1]} colonnes")
print("\nğŸ“‹ AperÃ§u des 5 premiÃ¨res lignes :")
print(df.head())

# 1.2 Informations sur le dataset
print("\nğŸ“‹ Informations sur les colonnes :")
print(df.info())

# 1.3 Supprimer les colonnes inutiles
colonnes_a_supprimer = ['Unnamed: 0', 'Total Volume', 'Total Bags']
print(f"\nğŸ—‘ï¸ Suppression des colonnes : {colonnes_a_supprimer}")
df = df.drop(columns=colonnes_a_supprimer)
print(f"âœ… Nouvelles dimensions : {df.shape[0]} lignes Ã— {df.shape[1]} colonnes")

# 1.4 Renommer les colonnes
renommage = {
    '4046': 'Quality1',
    '4225': 'Quality2',
    '4770': 'Quality3'
}
df = df.rename(columns=renommage)
print(f"\nâœ… Colonnes renommÃ©es : {renommage}")
print(f"ğŸ“‹ Nouvelles colonnes : {list(df.columns)}")

# 1.5 Convertir les dates
print(f"\nğŸ“… Type actuel de 'Date' : {df['Date'].dtype}")
df['Date'] = pd.to_datetime(df['Date'])
print(f"âœ… Type aprÃ¨s conversion : {df['Date'].dtype}")
print(f"ğŸ“† PÃ©riode couverte : du {df['Date'].min().strftime('%d/%m/%Y')} au {df['Date'].max().strftime('%d/%m/%Y')}")

# 1.6 VÃ©rification des valeurs manquantes
print("\nğŸ” Analyse des valeurs manquantes :")
valeurs_manquantes = df.isnull().sum()
print(valeurs_manquantes)
total_manquants = valeurs_manquantes.sum()
if total_manquants == 0:
    print("âœ… Aucune valeur manquante dans le dataset !")
else:
    print(f"âš ï¸ Total de valeurs manquantes : {total_manquants}")

# 1.7 VÃ©rification et suppression des doublons
nb_doublons = df.duplicated().sum()
print(f"\nğŸ” Nombre de lignes dupliquÃ©es : {nb_doublons}")
if nb_doublons > 0:
    print(f"âš ï¸ {nb_doublons} doublons dÃ©tectÃ©s ! Suppression en cours...")
    df = df.drop_duplicates()
    print(f"âœ… Doublons supprimÃ©s. Nouvelles dimensions : {df.shape}")
else:
    print("âœ… Aucun doublon dÃ©tectÃ© !")

# 1.8 RÃ©sumÃ© du dataset nettoyÃ©
print("\n" + "=" * 60)
print("ğŸ“Š RÃ‰SUMÃ‰ DU DATASET NETTOYÃ‰")
print("=" * 60)
print(f"ğŸ“ˆ Dimensions : {df.shape[0]} lignes Ã— {df.shape[1]} colonnes")
print(f"ğŸ¯ Variable cible : AveragePrice")
print(f"   - Min : {df['AveragePrice'].min():.2f} $")
print(f"   - Max : {df['AveragePrice'].max():.2f} $")
print(f"   - Moyenne : {df['AveragePrice'].mean():.2f} $")
print(f"ğŸ·ï¸ Types d'avocats : {df['type'].unique().tolist()}")
print(f"ğŸŒ Nombre de rÃ©gions : {df['region'].nunique()}")

# =============================================================================
# Ã‰TAPE 2 : PRÃ‰PARER LES DONNÃ‰ES POUR LE MODÃˆLE
# =============================================================================
print("\n" + "=" * 60)
print("ğŸ”§ Ã‰TAPE 2 : PRÃ‰PARER LES DONNÃ‰ES POUR LE MODÃˆLE")
print("=" * 60)

# 2.1 DÃ©finition des features (X) et de la cible (y)
X = df.drop(columns=['AveragePrice', 'Date'])
y = df['AveragePrice']

print(f"\nğŸ¯ Variable cible (y) : AveragePrice")
print(f"ğŸ“Š Dimensions de X : {X.shape}")
print(f"ğŸ“Š Dimensions de y : {y.shape}")

# 2.2 DÃ©finition des colonnes numÃ©riques et catÃ©goriques
colonnes_numeriques = ['Quality1', 'Quality2', 'Quality3', 'Small Bags', 'Large Bags', 'XLarge Bags', 'year']
colonnes_categoriques = ['type', 'region']

print(f"\nğŸ”¢ Colonnes numÃ©riques ({len(colonnes_numeriques)}) : {colonnes_numeriques}")
print(f"ğŸ·ï¸ Colonnes catÃ©goriques ({len(colonnes_categoriques)}) : {colonnes_categoriques}")

# 2.3 CrÃ©ation du ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), colonnes_numeriques),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), colonnes_categoriques)
    ],
    remainder='drop'
)

print("\nâœ… ColumnTransformer crÃ©Ã© avec succÃ¨s !")
print("   - Colonnes numÃ©riques â†’ StandardScaler")
print("   - Colonnes catÃ©goriques â†’ OneHotEncoder")

# 2.4 Division des donnÃ©es
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

# Conversion explicite en DataFrame/Series pandas
X_train = pd.DataFrame(X_train)
X_test = pd.DataFrame(X_test)
y_train = pd.Series(y_train)
y_test = pd.Series(y_test)

print(f"\nğŸ“Š Division des donnÃ©es :")
print(f"   - Ensemble d'entraÃ®nement : {len(X_train)} Ã©chantillons (80%)")
print(f"   - Ensemble de test : {len(X_test)} Ã©chantillons (20%)")

# =============================================================================
# Ã‰TAPE 3 : CONSTRUIRE ET ENTRAÃNER LE MODÃˆLE
# =============================================================================
print("\n" + "=" * 60)
print("ğŸ¤– Ã‰TAPE 3 : CONSTRUIRE ET ENTRAÃNER LE MODÃˆLE")
print("=" * 60)

# 3.1 CrÃ©ation du modÃ¨le XGBRegressor
xgb_model = XGBRegressor(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42,
    n_jobs=-1
)

# 3.2 CrÃ©ation du pipeline complet
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', xgb_model)
])

print("\nâœ… Pipeline crÃ©Ã© avec succÃ¨s !")
print("   - Ã‰tape 1 : PrÃ©traitement (ColumnTransformer)")
print("   - Ã‰tape 2 : ModÃ¨le (XGBRegressor)")

# 3.3 EntraÃ®nement du modÃ¨le
print("\nğŸš€ EntraÃ®nement du modÃ¨le en cours...")
start_time = time.time()

pipeline.fit(X_train, y_train)

training_time = time.time() - start_time
print(f"âœ… ModÃ¨le entraÃ®nÃ© avec succÃ¨s !")
print(f"â±ï¸ Temps d'entraÃ®nement : {training_time:.2f} secondes")

# =============================================================================
# Ã‰TAPE 4 : Ã‰VALUATION ET SAUVEGARDE DU MODÃˆLE
# =============================================================================
print("\n" + "=" * 60)
print("ğŸ“ˆ Ã‰TAPE 4 : Ã‰VALUATION ET SAUVEGARDE DU MODÃˆLE")
print("=" * 60)

# 4.1 PrÃ©dictions
y_pred = pipeline.predict(X_test)
y_train_pred = pipeline.predict(X_train)

print("\nâœ… PrÃ©dictions effectuÃ©es !")

# 4.2 Calcul des mÃ©triques
rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
r2_train = r2_score(y_train, y_train_pred)

rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))
r2_test = r2_score(y_test, y_pred)

print("\n" + "-" * 50)
print("ğŸ“Š PERFORMANCES DU MODÃˆLE")
print("-" * 50)
print(f"\nğŸ“ Ensemble d'ENTRAÃNEMENT :")
print(f"   - RMSE : {rmse_train:.4f} $")
print(f"   - RÂ²   : {r2_train:.4f} ({r2_train*100:.2f}%)")

print(f"\nğŸ§ª Ensemble de TEST :")
print(f"   - RMSE : {rmse_test:.4f} $")
print(f"   - RÂ²   : {r2_test:.4f} ({r2_test*100:.2f}%)")

print(f"\nğŸ“ˆ InterprÃ©tation :")
print(f"   - Le modÃ¨le explique {r2_test*100:.1f}% de la variance des prix")
print(f"   - L'erreur moyenne de prÃ©diction est de Â±{rmse_test:.3f} $")

# VÃ©rification du surapprentissage
if r2_train - r2_test > 0.1:
    print("\nâš ï¸ Attention : Possible surapprentissage dÃ©tectÃ© !")
else:
    print("\nâœ… Pas de surapprentissage significatif dÃ©tectÃ©")

# 4.3 Comparaison des prÃ©dictions
print("\nğŸ“‹ Comparaison des 10 premiÃ¨res prÃ©dictions :")
y_test_array = np.array(y_test)
comparaison = pd.DataFrame({
    'Prix RÃ©el ($)': np.round(y_test_array[:10], 2),
    'Prix PrÃ©dit ($)': np.round(y_pred[:10], 2),
    'Erreur ($)': np.round(y_test_array[:10] - y_pred[:10], 3)
})
print(comparaison.to_string(index=False))

# 4.4 Visualisations
print("\nğŸ“Š GÃ©nÃ©ration des graphiques...")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Graphique 1 : Scatter plot
ax1 = axes[0]
ax1.scatter(y_test, y_pred, alpha=0.5, edgecolors='k', linewidth=0.5)
y_min, y_max = float(np.min(y_test)), float(np.max(y_test))
ax1.plot([y_min, y_max], [y_min, y_max], 'r--', lw=2, label='PrÃ©diction parfaite')
ax1.set_xlabel('Prix RÃ©el ($)', fontsize=12)
ax1.set_ylabel('Prix PrÃ©dit ($)', fontsize=12)
ax1.set_title(f'PrÃ©dictions vs Valeurs RÃ©elles\nRÂ² = {r2_test:.4f}', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

# Graphique 2 : Distribution des erreurs
ax2 = axes[1]
erreurs = y_test - y_pred
ax2.hist(erreurs, bins=50, edgecolor='black', alpha=0.7, color='steelblue')
ax2.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Erreur = 0')
ax2.set_xlabel('Erreur de prÃ©diction ($)', fontsize=12)
ax2.set_ylabel('FrÃ©quence', fontsize=12)
ax2.set_title(f'Distribution des Erreurs\nRMSE = {rmse_test:.4f} $', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('model_evaluation.png', dpi=150, bbox_inches='tight')
plt.show()

print("âœ… Graphiques sauvegardÃ©s : model_evaluation.png")

# 4.5 Sauvegarde du modÃ¨le
nom_fichier = 'avocado_price_model.pkl'
joblib.dump(pipeline, nom_fichier)

taille_fichier = os.path.getsize(nom_fichier) / (1024 * 1024)

print("\n" + "-" * 50)
print("ğŸ’¾ SAUVEGARDE DU MODÃˆLE")
print("-" * 50)
print(f"âœ… Pipeline sauvegardÃ© avec succÃ¨s !")
print(f"ğŸ“ Fichier : {nom_fichier}")
print(f"ğŸ“¦ Taille : {taille_fichier:.2f} MB")

# 4.6 VÃ©rification du chargement
pipeline_charge = joblib.load(nom_fichier)
y_pred_verif = pipeline_charge.predict(X_test.head(5))

if np.allclose(y_pred[:5], y_pred_verif):
    print("âœ… VÃ©rification : Le modÃ¨le se charge et fonctionne correctement !")

# =============================================================================
# RÃ‰SUMÃ‰ FINAL
# =============================================================================
print("\n" + "ğŸ¥‘" * 30)
print("\n" + "=" * 60)
print("ğŸ“Š RÃ‰SUMÃ‰ FINAL DU PROJET")
print("=" * 60)

print(f"\nğŸ“ DONNÃ‰ES :")
print(f"   - Dataset original : {len(df)} Ã©chantillons")
print(f"   - Features : {X.shape[1]} colonnes")
print(f"   - EntraÃ®nement : {len(X_train)} Ã©chantillons (80%)")
print(f"   - Test : {len(X_test)} Ã©chantillons (20%)")

print(f"\nğŸ”§ PRÃ‰TRAITEMENT :")
print(f"   - StandardScaler sur {len(colonnes_numeriques)} colonnes numÃ©riques")
print(f"   - OneHotEncoder sur {len(colonnes_categoriques)} colonnes catÃ©goriques")

print(f"\nğŸ¤– MODÃˆLE : XGBRegressor")
print(f"   - n_estimators : 100")
print(f"   - max_depth : 6")
print(f"   - learning_rate : 0.1")

print(f"\nğŸ“ˆ PERFORMANCES (Test) :")
print(f"   - RMSE : {rmse_test:.4f} $")
print(f"   - RÂ²   : {r2_test:.4f} ({r2_test*100:.2f}%)")

print(f"\nğŸ’¾ FICHIERS GÃ‰NÃ‰RÃ‰S :")
print(f"   - {nom_fichier} (modÃ¨le)")
print(f"   - model_evaluation.png (graphiques)")

print("\n" + "=" * 60)
print("ğŸš€ Le modÃ¨le est prÃªt Ã  Ãªtre utilisÃ© !")
print("=" * 60)
print("\n" + "ğŸ¥‘" * 30)

# =============================================================================
# EXEMPLE D'UTILISATION DU MODÃˆLE
# =============================================================================
print("\n" + "=" * 60)
print("ğŸ”® EXEMPLE D'UTILISATION DU MODÃˆLE")
print("=" * 60)

# Exemple de prÃ©diction
exemple = pd.DataFrame({
    'Quality1': [5000],
    'Quality2': [10000],
    'Quality3': [2000],
    'Small Bags': [3000],
    'Large Bags': [500],
    'XLarge Bags': [100],
    'year': [2023],
    'type': ['organic'],
    'region': ['LosAngeles']
})

prix_predit = pipeline_charge.predict(exemple)[0]

print("\nğŸ“‹ CaractÃ©ristiques de l'avocat :")
for col in exemple.columns:
    print(f"   - {col}: {exemple[col].values[0]}")

print(f"\nğŸ’° Prix prÃ©dit : {prix_predit:.2f} $")
print("=" * 60)

